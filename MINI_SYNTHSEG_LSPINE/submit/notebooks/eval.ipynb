{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0ee841",
   "metadata": {},
   "source": [
    "# 평가 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352f362",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models.unet import UNet, compute_dice_per_class\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5f791",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_path = \"../data/SPIDER_T2_val/images/sample_T2.png\"\n",
    "label_path = \"../data/SPIDER_T2_val/labels/sample_label.png\"\n",
    "\n",
    "img = np.array(Image.open(img_path)).astype(np.float32)\n",
    "label = np.array(Image.open(label_path)).astype(np.int64)\n",
    "\n",
    "img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "img_torch = torch.tensor(img_norm).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40217007",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 14\n",
    "\n",
    "model_A = UNet(in_channels=1, num_classes=num_classes)\n",
    "model_B = UNet(in_channels=1, num_classes=num_classes)\n",
    "\n",
    "model_A.load_state_dict(torch.load(\"../models/saved/model_A_synthetic.pth\", map_location=\"cpu\"))\n",
    "model_B.load_state_dict(torch.load(\"../models/saved/model_B_real.pth\", map_location=\"cpu\"))\n",
    "\n",
    "model_A.eval()\n",
    "model_B.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cc05e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_A = model_A(img_torch)\n",
    "    pred_B = model_B(img_torch)\n",
    "\n",
    "pred_A = pred_A.argmax(1)[0]\n",
    "pred_B = pred_B.argmax(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac7b1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dice_A = compute_dice_per_class(pred_A, torch.tensor(label), num_classes=num_classes)\n",
    "dice_B = compute_dice_per_class(pred_B, torch.tensor(label), num_classes=num_classes)\n",
    "\n",
    "dice_A, dice_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bfd8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.imshow(label, cmap=\"tab20\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Prediction — Model A (Synthetic)\")\n",
    "plt.imshow(pred_A, cmap=\"tab20\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Prediction — Model B (Real)\")\n",
    "plt.imshow(pred_B, cmap=\"tab20\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abae09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classes = list(range(num_classes))\n",
    "vals_A = [dice_A[c] for c in classes]\n",
    "vals_B = [dice_B[c] for c in classes]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(classes, vals_A, alpha=0.6, label=\"Model A Synthetic\")\n",
    "plt.bar(classes, vals_B, alpha=0.6, label=\"Model B Real\")\n",
    "plt.legend()\n",
    "plt.title(\"Dice per Class Comparison (T2 Validation)\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"Dice Score\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
